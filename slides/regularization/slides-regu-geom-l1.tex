\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}


\title{Introduction to Machine Learning}

\begin{document}

\titlemeta{Regularization}{Geometry of L1 Regularization}
{figure/l1_reg_hess_01.png}{
    \item Approximate transformation of unregularized minimizer to regularized 
    \item Soft-Thresholding
}

\begin{vbframe} {L1-Regularization}
  

  \begin{itemize}
    \item The L1-regularized risk of a model $\fxt$ is

      \[
     \mathcal{R}_{\text{reg}}(\thetab) = \mathcal{R}_{\text{emp}}(\thetab) + \sum_j \lambda |\theta_j|
      \] 
      
      and the (sub-)gradient is:
      
      %$$\nabla_{\theta} \mathcal{R}_{\text{reg}}(\thetab) = 
      
      $$ \nabla_{\theta} \risket + \lambda \sign(\thetab) $$

    \item Unlike in $L2$, contribution to grad. doesn't scale with $\theta_j$ elements. 
    \item Again: quadratic Taylor approximation of $\mathcal{R}_{\text{emp}}(\thetab)$ around its minimizer $\thetah$, then regularize:
    %\item Again, this is an orthonormal design. r example, if the input features for a linear regression task have been decorrelated using PCA.
  \end{itemize}

 $$\mathcal{\tilde R}_{\text{reg}}(\thetab) = \mathcal{R}_{\text{emp}}(\thetah) +\ \frac{1}{2} (\thetab - \thetah)^T \bm{H} (\thetab - \thetah)  + \sum_j \lambda |\theta_j|$$
  
  \framebreak
  
  \begin{itemize}

\item To cheat and simplify, we assume the $\bm{H}$ is diagonal, with $H_{j,j} \geq 0$
  
    \item Now $\mathcal{\tilde R}_{\text{reg}}(\thetab)$ decomposes into sum over params $\theta_j$ (separable!):
  $$\mathcal{\tilde R}_{\text{reg}}(\thetab) = \mathcal{R}_{\text{emp}}(\thetah) + \sum_j \left[ \frac{1}{2} H_{j,j} (\theta_j - \hat{\theta}_j)^2 \right] + \sum_j \lambda |\theta_j|$$
  % where $\thetah$ is the minimizer of the unregularized risk $\risket$.
    \item We can minimize analytically:
     \begin{align*}\hat{\theta}_{\text{lasso},j} &= \sign(\hat{\theta}_j) \max \left\{ |\hat{\theta}_j| - \frac{\lambda}{H_{j,j}},0 \right\} \\
     &= \begin{cases} 
     \hat{\theta}_j + \frac{\lambda}{H_{j,j}} &, \text{if}   \;\hat{\theta}_j < -\frac{\lambda}{H_{j,j}} \\
       0 &, \text{if}   \;\hat{\theta}_j \in [-\frac{\lambda}{H_{j,j}}, \frac{\lambda}{H_{j,j}}] \\
     \hat{\theta}_j - \frac{\lambda}{H_{j,j}} &, \text{if}   \;\hat{\theta}_j > \frac{\lambda}{H_{j,j}} \\
     \end{cases}
     \end{align*}
  \item Shows how lasso (approx) transforms the normal minimizer
  \item If $H_{j,j} = 0$ exactly, $\thetah_{\text{lasso},j} = 0$
% This is also called the \textbf{soft thresholding}.

\framebreak

\item If  $0 < \hat{\theta}_j \leq \frac{\lambda}{H_{j,j}}$ or $0 > \hat{\theta}_j \geq -\frac{\lambda}{H_{j,j}}$, the optimal value of $\theta_j$ (for the regularized risk) is $0$ because the contribution of  $\risket$ to $\riskrt$ is overwhelmed by the L1 penalty, which forces it to be $0$.

\begin{figure}
\includegraphics[width=0.7\textwidth]{figure/l1_reg_hess_01.png}\\
\end{figure}

  \end{itemize}
\framebreak
  \begin{itemize}
  
    \item If $0 < \frac{\lambda}{H_{j,j}} < \hat{\theta}_j$ or  $0 > -\frac{\lambda}{H_{j,j}} > \hat{\theta}_j$, the $L1$ penalty shifts the optimal value of $\theta_j$ toward 0 by the amount $\frac{\lambda}{H_{j,j}}$.

\vfill


\begin{figure}
\includegraphics[width=0.7\textwidth]{figure/l1_reg_hess_02.png}\\
\end{figure}
    \item Yellow dotted lines are limits from soft-thresholding

    \item Therefore, the L1 penalty induces sparsity in the parameter vector.
  \end{itemize}

  
\end{vbframe}

\endlecture
\end{document}