
\documentclass[11pt,compress,t,notes=noshow, xcolor=table]{beamer}
\input{../../style/preamble}
\input{../../latex-math/basic-math}
\input{../../latex-math/basic-ml}

\newcommand{\citebutton}[2]{%
\NoCaseChange{\resizebox{!}{9pt}{\protect\beamergotobutton{\href{#2}{#1}}}}%
}

\newcommand{\titlefigure}{figure_man/varsel_space.png}
\newcommand{\learninggoals}{
  \item Understand how wrapper methods work
  \item Understand how they could help in feature selection
  \item Know their advantages and disadvantages
}


\title{Supervised Learning}
\date{}

\begin{document}

  \lecturechapter{Wrapper methods}
  \lecture{Supervised Learning}

  \begin{vbframe}{Introduction}

    \begin{itemize}
      \item Wrapper methods emerged from the idea that different sets of features can be optimal for different learners.
      \item Use the learner itself to assess the quality of the feature sets.
      \item Evaluation on a test set or resampling techniques are used.
      \item A wrapper is nothing else than a discrete search strategy for $S$, where the test error of a learner as a function of $S$ is now the objective criterion.

    \end{itemize}


    \framebreak

    Wrappers have the following components:


    \begin{itemize}
      \item A set of starting values
      \item Operators to create new points out of the given ones
      \item A termination criterion
    \end{itemize}


    \begin{figure}
      \includegraphics[width=8cm]{figure_man/varsel_space.png}
      % \caption{Space of all feature sets for 4 features.
      % The indicated relationships between the sets insinuate a greedy search strategy which either adds or removes a feature.}
      % Übersetzung von:
      % Raum aller Feature-Mengen bei 4 Features. Die eingezeichnete Nachbarschaftsbeziehung unterstellt eine Art ,,gierige'' Suchstrategie, bei der wir entweder ein Feature hinzufügen oder entfernen.}
    \end{figure}


  \end{vbframe}

  \begin{vbframe}{Objective function}

    %\small

    Given $p$ features, the \textbf{best-subset selection problem} is to find a subset $S \subseteq \{ 1, \dots p \}$ optimizing objective $\Psi: \Omega \rightarrow \R$:
    \vspace{-0.1cm}
    %measuring the learner's generalization performance. The solution $S^*$ to the problem is
    $$S^{*}  \in \argmin_{{S \in \Omega}} \{ \Psi(S) \}$$
    %
    \vspace{-0.8cm}
    \begin{itemize}
    \setlength{\itemsep}{0.9em}
     \item $\Omega$  = search space of all feature subsets $S\subseteq\{ 1, \dots, p \}$. Usually we encode this by
      %(i.e., $\Omega \subseteq \mathcal{P}(\{ 1, \dots, p \})$, $\mathcal{P}$ denoting the power set) 
      bit vectors, i.e., $\Omega = \{0, 1\}^p$ (1 = feat. selected)
      %It will be clear from the context which variant we refer to.
     \item Objective $\Psi$ can be different functions, e.g., AIC/BIC for LM or cross-validated performance of a learner.
    \end{itemize}

    \begin{center}
     \includegraphics[width = 0.3\textwidth]{figure/searchspace_binary.png}\\
     \scriptsize{Hasse diagram (source: Wikipedia)}
    \end{center}
    %\normalsize
  \end{vbframe} 

  
 \begin{vbframe}{How difficult is best-subset selection?}

    \begin{itemize}
    \setlength{\itemsep}{1.2em}
      \item Size of search space = $2^p$, i.e., grows exponentially in $p$ as it is the power set of $\{1,\ldots,p\}$.
      \item Finding best subset is discrete combinatorial optimization problem also known as $L_0$ regularization.
     \item It can be shown that this problem unfortunately can not be solved efficiently in general (NP hard; see, e.g., \citebutton{Natarajan, 1995}{https://epubs.siam.org/doi/10.1137/S0097539792240406})
     \item We can avoid having to search the entire space by employing efficient search strategies, moving through the search space in a smart way that finds performant feature subsets.
     %\item By employing efficient search strategories, we can avoid searching the entire space.
    %\item Of course this does not mean that we have to search the entire space, since there are more efficient search strategies.
    %  \item Formally spoken: One can show that the problem is NP-hard!
    %  \item This means that the problem cannot be solved in polynomial (P) time: ${\mathcal{O}} (p^c)$, where $c \in \N$ indicates the degree o the polynom.
    % \end{blocki}
    % 
    % \framebreak
    % 
    % \begin{blocki}{How difficult is it to solve the introduced optimization problem, hence, to find the optimal feature set?}
    %  \item More precisely, the proof demonstrates that this problem cannot be approximated within any constant, unless P = NP.
    % 
    %   The latter means, that if you find an algorithm that solves a more difficult class of problems (than this optimization problem) in polynomial time, this implies that you found how to solve all easier problems (including our optimization problem) in polynomial time.
    % \item \textbf{Attention}: This does not imply that it is useless trying to construct strategies which work in practice!
    %\item Thus our problem now consists of moving through the search space in a smart and efficient way, thereby finding a particularly good set of features.
    \end{itemize}
  \end{vbframe}

  
  \begin{vbframe}{Greedy forward search}

    \begin{blocki}{}
      \item Let $S \subset \{1, \dots, p \}$, where $\{1, \dots p \}$ is an index set of all features.
      \item Start with the empty feature set $S = \emptyset$.
      \item For a given set $S$, generate all $S_j = S \cup \{j\}$ with $j \notin S$.
      \item Evaluate the classifier on all $S_j$ and use the best $S_j$.
      \item Iterate over this procedure.
      \item Terminate if:
        \begin{itemize}
          \item the performance measure doesn't improve enough.
          \item a maximum number of features is used.
          \item a given performance value is reached.
        \end{itemize}
    \end{blocki}

    \framebreak

    \textbf{Example for greedy forward search on iris data:}
    \begin{center}
    \includegraphics[width = 0.6\textwidth]{figure_man/wrapperanim1.png}
    \end{center}

    \framebreak

    \begin{center}
    \includegraphics[width = 0.65\textwidth]{figure_man/wrapperanim2.png}
    \end{center}

    \framebreak

    \begin{center}
    \includegraphics[width = 0.65\textwidth]{figure_man/wrapperanim3.png}
    \end{center}

    \framebreak

    \begin{center}
    \includegraphics[width = 0.65\textwidth]{figure_man/wrapperanim4.png}
    \end{center}

    \framebreak

    \begin{center}
    \includegraphics[width = 0.65\textwidth]{figure_man/wrapperanim5.png}
    \end{center}

    \framebreak

    \begin{center}
    \includegraphics[width = 0.65\textwidth]{figure_man/wrapperanim6.png}
    \end{center}
    
  \end{vbframe}


  \begin{vbframe}{Greedy backward search}


    \begin{blocki}{}
      \item Start with the full index set of features $S = \{1, \ldots, p\}$.
      \item For a given set $S$ generate all

      $S_j = S \setminus\{j\}$ with $j \in S$.
      \item Evaluate the classifier on all $S_j$\
        and use the best $S_j$.
      \item Iterate over this procedure.
      \item Terminate if:
        \begin{itemize}
          \item the performance drops drastically, or
          \item a given performance value is undershot.
        \end{itemize}
      \end{blocki}
    
  \end{vbframe}

  \begin{vbframe}{Extensions}

    \begin{itemize}
      \setlength{\itemsep}{1.0em}
      \item Eliminate or add several features at once to increase speed.
      \item Allow alternating forward and backward search.
      \item Randomly create candidate feature sets in each iteration.
      \item Continue search based on the set of features where an improvement is present.
      \item Use improvements of earlier iterations.
    \end{itemize}

    \framebreak

    \begin{algorithm}[H]
    \begin{algorithmic}[1]
      \State Start with a random set of features $S$ (bit vector $b$).
      \Repeat
      \State Flip a couple of bits in $b$ with probability $p$.
      \State Generate set $S^\prime$ and bit vector $b^\prime$.
      \State Measure the classifier's performance on $S^\prime$.
      \State If $S^\prime$ performs better than $S$, update $S \leftarrow S^\prime$, otherwise $S \leftarrow S$.
      \Until One of the following conditions is met:
        \begin{itemize}
          \item A given performance value is reached.
          \item Budget is exhausted.
        \end{itemize}
        \caption{A simple 1+1 genetic algorithm}
    \end{algorithmic}
    \end{algorithm}

    \end{vbframe}

  \begin{vbframe}{Wrappers}

    \begin{blocki}{Advantages:}
      \item Can be combined with every learner.
      \item Can be combined with every performance measure.
      \item Optimizes the desired criterion directly.
    \end{blocki}

    \lz

    \begin{blocki}{Disadvantages:}
      \item Evaluating the target function is expensive.
      \item Does not scale well if number of features becomes large.
      \item Does not use much structure or available information from our model.
    \end{blocki}

  \end{vbframe}

    % \framebreak
    %
    % <<size="tiny", echo=TRUE>>=
    % # specify the search strategy.
    % # We want to use forward search:
    % ctrl = makeFeatSelControlSequential(method = "sfs")
    % ctrl
    %
    % # Selected features
    % sfeats = selectFeatures(learner = "regr.lm", task = bh.task,
    %   resampling = rdesc, control = ctrl, show.info = FALSE)
    % sfeats
    % @
    %
    % \framebreak
    %
    % <<size="tiny", echo=TRUE>>=
    % # Visualize optimization path
    % analyzeFeatSelResult(sfeats)
    % @
    %
    % \framebreak
    %
    % <<size="tiny", echo=TRUE>>=
    % # Fuse a base-learner with a search strategy (here: sfs)
    % lrn = makeFeatSelWrapper("classif.rpart", resampling = rdesc,
    %   control = ctrl, show.info = FALSE)
    % res = resample(lrn, iris.task, resampling = rdesc,
    %   show.info = FALSE, models = TRUE, extract = getFeatSelResult)
    % res$extract[1:5]
    % @

  \endlecture
\end{document}

