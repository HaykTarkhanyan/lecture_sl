
Suppose you apply AdaBoost with a decision stump on the data set as in the following figure:

<<echo=FALSE, fig.align='center', fig.height=4, fig.width=4>>=
  # Define x 
  x<-c(1,3,5)
  # Define y
  y = c(-1, 1, -1)
  ## Make y-value=0
  x<-cbind(x,0)
  ## Plotting without box or axis with dot, representing data points                  
  plot(x, col=ifelse(y==1,'red','blue')
          ,bty='n',xaxt='n',yaxt='n',ylab='',xlab='',pch=16,cex=2)
  # add axis with label to the right
  axis(1, at=1:5, labels=1:5, las=1,pos=-0.12)
  # add axis labels
  mtext("x", side=1, line=-2, cex=1.5)
  # add a legend
  legend("topright", legend=c("y=1","y=-1"), col=c("red","blue"), pch=16, cex=0.7)

@


\begin{enumerate}
	\item 
		What would be a decision boundary for the first decision stump? 
		\lz
		\lz
		\lz
		\lz
		\lz
		\lz
	\item
		 How do the weights of the points change after the first iteration?
		\lz
		\lz
		\lz
		\lz
		\lz
		\lz
	\item 
		How many iterations are at least needed such that AdaBoost's training error is zero?
		\lz
		\lz
		\lz
		\lz
		\lz
		\lz
\end{enumerate}