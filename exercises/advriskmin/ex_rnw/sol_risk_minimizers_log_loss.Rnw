\begin{enumerate}
	\item
  \begin{align*}
    \pibayes_{c}  &= \argmin_{c \in \unitint} \E_{xy} \left[ L\left(y, c\right) \right] = \argmin_{c} \E_{y} \left[ L\left(y, c\right) \right]\\
    &= \argmin_{c} \E_{y} \left[ -y \log \left(c\right) - \left(1-y\right) \log \left(1-c\right) \right] \\
    &= \argmin_{c} - \log \left(c\right) \underbrace{\E_{y} \left[y\right]}_{=\P(y=1)=\pi} -\log \left(1-c\right)  \underbrace{\E_{y} \left[1-y\right]}_{=1-\pi} \\
    &= \argmin_{c} - \left[\pi \log \left(c\right) + \left(1-\pi\right) \log \left(1-c\right) \right]
  \end{align*}
  Taking the derivative and setting it to $0$:
  \begin{align*}
    &\Rightarrow \pd{}{c} - \left[\pi \log \left(c\right) + \left(1-\pi\right) \log \left(1-c\right) \right] \overset{!}{=} 0 \\
    &\begin{alignedat}{2}
      &\Rightarrow -\frac{\pi}{c} + \frac{1 - \pi}{1 - c} &&= 0 \\
      &\Rightarrow c (1 - \pi) &&= (1 - c) \pi \\
      &\Rightarrow c &&= \pi \\
      &\Rightarrow \pi_c^\ast &&= \mathbb{P}(y = 1)
    \end{alignedat}
  \end{align*}

\item
  \begin{align*}
    \risk_{l}(\pibayes_{c}) &= \E_{xy} \left[ L\left(y, \pi \right) \right]\\
    &= \E_{xy} \left[  -y \log \left( \pi \right) - \left(1-y\right) \log \left(1 - \pi \right)  \right] \\
    &= - \pi \log(\pi) - (1-\pi) log(1-\pi) \\
    &= H(y) \text{ (= Entropy!)}
  \end{align*}

\item
	The optimal constant model in terms of the \textit{empirical} risk $\thetavh$ is given by $\thetavh = \argmin_{\thetav \in \Theta} \risk_{emp}(\thetav)$.
  \begin{align*}
    \risk_{emp}(\thetav) &= \sumin L\left(\yi, \fxi\right)\\
    &= \sumin \log \left(1 + \exp(-\yi \thetav) \right)
  \end{align*}
  As $L(y, \thetav) = log\left(1 + \exp(-\yi\thetav)\right)$.
  Taking the derivative:
  \begin{align*}
    \pd{}{\thetav} \risk_{emp}(\thetav) &= \sumin \frac{1}{1+\exp(-\yi\thetav)} \left(+\exp(-\yi\thetav) \right) (-\yi)\\
    &= - \sumin \yi \frac{\exp(c)}{1 + \exp(c)}\\
    &= - \sum\limits_{\yi=1}^n 1 \frac{\exp(-\thetav)}{1+\exp(-\thetav)} - \sum\limits_{\yi=-1}^n -1 \frac{\exp(\thetav)}{1+\exp(\thetav)}\\
    &\overset{!}{=} 0
  \end{align*}
  This is equivalent to:
  \begin{align*}
    \sum\limits_{\yi=-1}^n \frac{\exp(\thetav)}{1+\exp(\thetav)} &= \sum\limits_{\yi=1}^n \frac{\exp(-\thetav)}{1+\exp(-\thetav)}\\
    n_{-} \frac{\exp(\thetav)}{1+\exp(\thetav)} &= n_{+} \frac{1}{1+\exp(\thetav)}\\
    \frac{n_{+}}{n_{-}} &= \exp(\thetav)\\
    \thetav &= \log(\frac{n_{+}}{n_{-}})
  \end{align*}


\end{enumerate}
