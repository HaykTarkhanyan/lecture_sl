\begin{enumerate}
	\item
  \begin{align*}
    \pibayes_{c}  &= \argmin_{c \in \unitint} \E_{xy} \left[ L\left(y, c\right) \right] = \argmin_{c} \E_{y} \left[ L\left(y, c\right) \right]\\
    &= \argmin_{c} \E_{y} \left[ -y \log \left(c\right) - \left(1-y\right) \log \left(1-c\right) \right] \\
    &= \argmin_{c} - \log \left(c\right) \underbrace{\E_{y} \left[y\right]}_{=\P(y=1)=\pi} -\log \left(1-c\right)  \underbrace{\E_{y} \left[1-y\right]}_{=1-\pi} \\
    &= \argmin_{c} - \left[\pi \log \left(c\right) + \left(1-\pi\right) \log \left(1-c\right) \right]
  \end{align*}
  Taking the derivative with respect to $c$ and setting it to $0$:
  \begin{align*}
    &\Rightarrow \pd{}{c} \left[- \pi \log \left(c\right) + \left(1-\pi\right) \log \left(1-c\right) \right] \overset{!}{=} 0 \\
    &\begin{alignedat}{2}
      &\Rightarrow -\frac{\pi}{c} + \frac{1 - \pi}{1 - c} &&= 0 \\
      &\Rightarrow c (1 - \pi) &&= (1 - c) \pi \\
      &\Rightarrow c &&= \pi \\
      &\Rightarrow \pibayes_{c} &&= \mathbb{P}(y = 1)
    \end{alignedat}
  \end{align*}

\item
  \begin{align*}
    \risk_{l}(\pibayes_{c}) &= \E_{xy} \left[ L\left(y, \pi \right) \right]\\
    &= \E_{y} \left[  -y \log \left( \pi \right) - \left(1-y\right) \log \left(1 - \pi \right)  \right] \\
    &= - \pi \log(\pi) - (1-\pi) log(1-\pi) \\
    &= H(y) \text{ (= Entropy!)}
  \end{align*}

\item
	$\thetah$, the optimal constant model in terms of the \textit{empirical} risk, is given by $\thetah = \argmin_{\theta \in \Theta} \risk_{emp}(\theta)$.
  \begin{align*}
    \risk_{emp}(\theta) &= \sumin L\left(\yi, \fxi\right)\\
    &= \sumin \log \left(1 + \exp(-\yi \theta) \right)
  \end{align*}
  As $L(y, \theta) = log\left(1 + \exp(-\yi\theta)\right)$.
  Taking the derivative:
  \begin{align*}
    \pd{}{\theta} \risk_{emp}(\theta) &= \sumin \frac{1}{1+\exp(-\yi\theta)} \left(+\exp(-\yi\theta) \right) (-\yi)\\
    &= - \sumin \yi \frac{\exp(c)}{1 + \exp(c)}\\
    &= - \sum\limits_{\yi=1}^n (1) \frac{\exp(-\theta)}{1+\exp(-\theta)} - \sum\limits_{\yi=-1}^n (-1) \frac{\exp(\theta)}{1+\exp(\theta)}\\
    &\overset{!}{=} 0
  \end{align*}
  This is equivalent to:
  \begin{align*}
    \sum\limits_{\yi=-1}^n \frac{\exp(\theta)}{1+\exp(\theta)} &= \sum\limits_{\yi=1}^n \frac{\exp(-\theta)}{1+\exp(-\theta)}\\
    n_{-} \frac{\exp(\theta)}{1+\exp(\theta)} &= n_{+} \frac{1}{1+\exp(\theta)}\\
    \frac{n_{+}}{n_{-}} &= \exp(\theta)\\
    \theta &= \log(\frac{n_{+}}{n_{-}})
  \end{align*}


\end{enumerate}
