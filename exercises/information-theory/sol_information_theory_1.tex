\documentclass[a4paper]{article}
\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\makeatletter
\@ifundefined{AddToHook}{}{\AddToHook{package/xcolor/after}{\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}}}
\makeatother
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\makeatletter
\@ifundefined{AddToHook}{}{\AddToHook{package/xcolor/after}{
\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
}}
\makeatother
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\newcommand{\SweaveOpts}[1]{}  % do not interfere with LaTeX
\newcommand{\SweaveInput}[1]{} % because they are not real TeX commands
\newcommand{\Sexpr}[1]{}       % will only be parsed by R




\usepackage[utf8]{inputenc}
%\usepackage[ngerman]{babel}
\usepackage{a4wide,paralist}
\usepackage{amsmath, amssymb, xfrac, amsthm}
\usepackage{dsfont}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{framed}
\usepackage{multirow}
\usepackage{bytefield}
\usepackage{csquotes}
\usepackage[breakable, theorems, skins]{tcolorbox}
\usepackage{hyperref}
\usepackage{cancel}
\usepackage{bm}


\input{../../style/common}

\tcbset{enhanced}

\DeclareRobustCommand{\mybox}[2][gray!20]{%
	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
	\fi
}

\DeclareRobustCommand{\myboxshow}[2][gray!20]{%
%	\iffalse
	\begin{tcolorbox}[   %% Adjust the following parameters at will.
		breakable,
		left=0pt,
		right=0pt,
		top=0pt,
		bottom=0pt,
		colback=#1,
		colframe=#1,
		width=\dimexpr\linewidth\relax,
		enlarge left by=0mm,
		boxsep=5pt,
		arc=0pt,outer arc=0pt,
		]
		#2
	\end{tcolorbox}
%	\fi
}


%exercise numbering
\renewcommand{\theenumi}{(\alph{enumi})}
\renewcommand{\theenumii}{\roman{enumii}}
\renewcommand\labelenumi{\theenumi}


\font \sfbold=cmssbx10

\setlength{\oddsidemargin}{0cm} \setlength{\textwidth}{16cm}


\sloppy
\parindent0em
\parskip0.5em
\topmargin-2.3 cm
\textheight25cm
\textwidth17.5cm
\oddsidemargin-0.8cm
\pagestyle{empty}

\newcommand{\kopf}[2]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Introduction to Machine Learning \hfill Exercise sheet #1\\
	 \url{https://slds-lmu.github.io/i2ml/} \hfill #2}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newcommand{\kopfic}[2]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Introduction to Machine Learning \hfill Live Session #1\\
	 \url{https://slds-lmu.github.io/i2ml/} \hfill #2}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newcommand{\kopfsl}[2]{
\hrule
\vspace{.15cm}
\begin{minipage}{\textwidth}
%akwardly i had to put \" here to make it compile correctly
	{\sf\bf Supervised Learning \hfill Exercise sheet #1\\
	 \url{https://slds-lmu.github.io/i2ml/} \hfill #2}
\end{minipage}
\vspace{.05cm}
\hrule
\vspace{1cm}}

\newenvironment{allgemein}
	{\noindent}{\vspace{1cm}}

\newcounter{aufg}
\newenvironment{aufgabe}[1]
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}: #1}\\ \noindent}
	{\vspace{0.5cm}}

\newcounter{loes}
\newenvironment{loesung}[1]
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}: #1}\\\noindent}
	{\bigskip}
	
\newenvironment{bonusaufgabe}
	{\refstepcounter{aufg}\textbf{Exercise \arabic{aufg}*\footnote{This
	is a bonus exercise.}:}\\ \noindent}
	{\vspace{0.5cm}}

\newenvironment{bonusloesung}
	{\refstepcounter{loes}\textbf{Solution \arabic{loes}*:}\\\noindent}
	{\bigskip}



\begin{document}
% !Rnw weave = knitr



\input{../../latex-math/basic-math.tex}
\input{../../latex-math/basic-ml.tex}

\kopfsl{6}{Information Theory}

\loesung{Entropy}{

A fair die is rolled at the same time as a fair coin is tossed. Let $A$ be the number on the upper surface of the die and let $B$ describe the outcome of the coin toss, where
$$
B = 
\begin{cases}
1, \quad \text{head}\,,\\
0, \quad \text{tail}\,.
\end{cases}
$$
Two random variables $X$ and $Y$ are given by $X = A + B$ and $Y = A-B$, respectively. 

\begin{enumerate}
\item{Calculate the entropies $H(X)$ and $H(Y)$, the conditional entropies $H(Y|X)$ and $H(X|Y)$, the joint entropy $H(X,Y)$ and the mutual information $I(X;Y)$.


\underline{\textbf{Solution:}}


Let $a,b,x,$ and $y$ denote the realisations of the random variables $A, B, X,$ and $Y$, respectively. Each event $(a,b)$ is associated with exactly one event $(x,y)$ and the probability for such an event is given by
$$
p_{AB}(a,b) = p_{XY}(x,y) = \frac{1}{6}\cdot \frac{1}{2} = \frac{1}{12}
$$
Consequently, we obtain for the joint entropy
\begin{align*}
H(X,Y) &= - \sum_{x,y} p_{X,Y}(x,y) \log_2 p_{XY}(x,y) = -12\cdot \frac{1}{12}\log_2 \frac{1}{12} \\
 &= \log_2 12 \\
 &= 2 + \log_2 3
\end{align*}

Below we list the possible values of the random variables $X$ and $Y$, the associated events $(a,b)$, and the probability masses $p_X (x)$ and $p_Y(y).$
\begin{center}
\begin{tabular}{clc}
\hline
$x$ & events $(a,b)$ & $p_X(x)$ \\
\hline
1   & $(1,0)$ & $1/12$ \\
2   & $(2,0), (1,1)$ & $1/6$\\
3   & $(3,0), (2,1)$ & $1/6$\\
4   & $(4,0), (3,1)$ & $1/6$\\
5   & $(5,0), (4,1)$ & $1/6$\\
6   & $(6,0), (5,1)$ & $1/6$\\
7   & $(6,1)$ & $1/12$\\
\hline
\end{tabular}
\quad \quad
\begin{tabular}{clc}
\hline
$y$ & events $(a,b)$ & $p_Y(y)$ \\
\hline
0 & $(1,1)$ & $1/12$\\
1 & $(1,0), (2,1)$ & $1/6$\\
2 & $(2,0), (3,1)$ & $1/6$\\
3 & $(3,0), (4,1)$ & $1/6$\\
4 & $(4,0), (5,1)$ & $1/6$\\
5 & $(5,0), (6,1)$ & $1/6$\\
6 & $(6,0)$ & $1/12$\\
\hline
\end{tabular}
\end{center}

The random variable $X = A + B$ can take the values 1 to 7. The probability masses $p_X(x)$ for the values 1 and 7 are equal to $1/12$, since they correspond to exactly one event. The probability masses for the values 2 to 6 are equal to $1/6$, since each of these values corresponds to two events $(a,b)$. An analogue result is obtained for the random variable $Y =  A-B$.

The marginal entropies are given by
\begin{align*}
H(X) &= -\sum_x p_X(x) \log_2 p_X(x) \\
 &= -2\cdot \frac{1}{12}\log_2 \frac{1}{12} - 5\cdot \frac{1}{6}\log_2 \frac{1}{6} \\
 &= \frac{1}{6}\cdot\left( \log_2 4 + \log_2 3 \right) + \frac{5}{6}\cdot \left( \log_2 2 + \log_2 3 \right) \\
 &= \frac{7}{6} + \log_2 3
\end{align*}
and for $Y$

\begin{align*}
H(Y) &= -\sum_y p_Y(y) \log_2 p_Y(y) \\
 &= -2\cdot \frac{1}{12}\log_2 \frac{1}{12} - 5\cdot \frac{1}{6}\log_2 \frac{1}{6} \\
 &= \frac{1}{6}\cdot\left( \log_2 4 + \log_2 3 \right) + \frac{5}{6}\cdot \left( \log_2 2 + \log_2 3 \right) \\
 &= \frac{7}{6} + \log_2 3
\end{align*}


We can determine the conditional entropies using
$$
H(X|Y) = H(X,Y) - H(Y) =2 + \log_2 3-\frac{7}{6}-\log_2 3 = \frac{5}{6} 
$$

$$
H(Y|X) = H(X,Y) - H(X) =2 + \log_2 3-\frac{7}{6}-\log_2 3 = \frac{5}{6} 
$$

The mutual information $I(X;Y)$ can be determined acording to
$$
I(X;Y) = H(X) - H(X|Y) = \frac{7}{6} + \log_2 3 - \frac{5}{6} = \frac{1}{3} + \log_2 3
%\sum_{x,y} p_{XY}(x,y) \log_2 \frac{p_{XY}(x,y)}{p_X(x)p_Y(y)}}
$$
or
$$
I(X;Y) = H(Y) - H(Y|X) = \frac{7}{6} + \log_2 3 - \frac{5}{6} = \frac{1}{3} + \log_2 3
%\sum_{x,y} p_{XY}(x,y) \log_2 \frac{p_{XY}(x,y)}{p_X(x)p_Y(y)}}
$$
}

\item{Show that, for independent discrete random variables $X$ and $Y$,
$$
I(X;X+Y) - I(Y;X+Y) = H(X) - H(Y)
$$

\underline{\textbf{Solution:}}


Using the definition of mutual information for discrete random variables, $I(X;Y) = H(Y)- H(Y|X)$, we can write
\begin{align*}
 I(X;X+Y) - I(Y;X+Y) &= H(X+Y)-H(X+Y|X) - H(X+Y)+H(X+Y|Y) \\
 &= H(X|Y) - H(Y|X) \\
 &= H(X) - H(Y)\,.
\end{align*}

The first step follows from the fact that modifying the mean of a pmf doesn't change the entropy. For the second step, we used the fact that the conditional entropy $H(X|Y)$ is equal to the marginal entropy $H(X)$ for independent random variables $X$ and $Y$.

}



\end{enumerate}
}

\end{document}
