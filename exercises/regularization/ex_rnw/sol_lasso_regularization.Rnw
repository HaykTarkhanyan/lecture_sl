\begin{enumerate}
        
    \item 

        First of all, we will use the  fact that $\Xmat$ has orthonormal columns to show that:

        \begin{equation}\label{eq:solve_b}
            \begin{aligned}
                \thetavh &= \left(\underbrace{{\Xmat}^T \Xmat}_{\id}\right)^{-1} \Xmat^T\yv \\
                \thetavh &= \Xmat^T \yv  
            \end{aligned}
        \end{equation}

        We will now use the result of eq. \ref{eq:solve_b} to show that:
        \begin{equation}
            \begin{aligned}
                \argmin_{\thetav}  \riskrt &= \argmin_{\thetav} \frac12 \sum_{i=1}^n \left( \yi - \thetav^\top \Xmat^{(i)} \right)^2 + \lambda \sum_{i=1}^p  |\theta_i| \\
                &= \argmin_{\thetav}  \frac12  \| \yv - \Xmat \thetav  \|_2^2 + \lambda \|\thetav\|_1 \\
                &= \argmin_{\thetav} \frac12 ( \yv - \Xmat \thetav)^T ( \yv - \Xmat \thetav) + \lambda \|\thetav\|_1 \\ 
                &= \argmin_{\thetav}  \frac12 \left(\underbrace{\yv^T \yv}_{indep. \  of \  \thetav} - 2 \underbrace{\yv^T \Xmat}_{\thetav^T} \thetav + \thetav^T \underbrace{\Xmat^T \Xmat}_{\id} \thetav \right) + \lambda \|\thetav\|_1 \\
                &= \argmin_{\thetav} - \thetavh^T \thetav  + \frac{\thetav^T \thetav}{2} + \lambda \|\thetav\|_1 \\
                &= \argmin_{\thetav} \sum_{i=1}^p	- \thetah_{i}\theta_i + \frac{\theta_i^2}{2} + \lambda|\theta_i|.
            \end{aligned}
        \end{equation}

    \item

        The advantage of this representation if we are interested in finding $\thetav$ is that we can optimize each $g_i(\theta_i)$ separately to get optimal entries for $\theta_1,\dots,\theta_p$.

    \item 

        Let's use the hint and compare $g_i(\theta_i)$ with $g_i(-\theta_i)$, for the case where $\theta_i > 0$ :

        \begin{equation} \label{eq:compare_gi}
            \begin{aligned}
                g_i(\theta_i) &= - \thetah_{i}\theta_i + \frac{\theta_i^2}{2} + \lambda|\theta_i| \\
                g_i(-\theta_i) &= + \thetah_{i}\theta_i + \frac{(-\theta_i)^2}{2} + \lambda|\theta_i| \\
            \end{aligned}
        \end{equation}

        We also know that non-positive $\theta_i$ have always a greater or equal value for $g_i(\theta_i)$ than than their positive counterpart:
        \begin{equation} \label{eq:compare_gi_2}
            \begin{aligned}
                \theta_i > 0 \longrightarrow g_i(\theta_i) \leq g_i(-\theta_i)
            \end{aligned}
        \end{equation}

        The second and third term of both equations in eq. \ref{eq:compare_gi} are equivalent, so we can ignore them. 
        Accordingly, to comply with the condition from  eq. \ref{eq:compare_gi_2}, the minimizer $\theta_i^*$   must be non-negative.

        \begin{equation}
            \begin{aligned}
                - \thetah_{i}\theta_i \leq \thetah_{i}\theta_i \longrightarrow \theta_i^* \geq 0
            \end{aligned}
        \end{equation}
    
    \item 

        To calculate the minimizer $\theta_i^*$, we will derive with respect to the parameter and set the derivative to zero:

        \begin{equation}
            \begin{aligned}
                \frac{\partial g_i(\theta_i)}{\partial \theta_i} &= - \thetah_{i} + \theta_i + \underbrace{\lambda}_{\theta_i > 0} \\
                &= - \thetah_{i} + \theta_i + \lambda  \stackrel{!}{=} 0  \longrightarrow \theta_i = \underbrace{\thetah_{i} -\lambda}_{ \geq 0} \\
                \theta_i^* &=  \underbrace{\thetah_i - \lambda}_{ \geq 0} \\
                &= max(0,  \thetah_i  - \lambda) \\
            \end{aligned}
        \end{equation}
    
    \item 

        Let's use the hint again and compare $g_i(\theta_i)$ with $g_i(-\theta_i)$, for the case where $\theta_i < 0$ :

        \begin{equation} \label{eq:compare_gi_negative}
            \begin{aligned}
                g_i(\theta_i) &= - \thetah_{i}\theta_i + \frac{\theta_i^2}{2} + \lambda|\theta_i| \\
                g_i(-\theta_i) &= + \thetah_{i}\theta_i + \frac{(-\theta_i)^2}{2} + \lambda|\theta_i| \\
            \end{aligned}
        \end{equation}

        \begin{equation} \label{eq:compare_gi_negative_2}
            \begin{aligned}
                \theta_i < 0 \longrightarrow g_i(\theta_i) \geq g_i(-\theta_i)
            \end{aligned}
        \end{equation}

        The second and third term in both equations of \ref{eq:compare_gi_negative} are equivalent. Using the condition from eq. \ref{eq:compare_gi_negative_2}, we can conclude that the minimizer $\theta_i^*$ must be non-positive.

        \begin{equation}
            \begin{aligned}
                - \thetah_{i}\theta_i \geq \thetah_{i}\theta_i \longrightarrow \theta_i^* \leq 0
            \end{aligned}
        \end{equation}

    \item 

        Calculating the derivative again and setting it to zero, we get:

        \begin{equation} \label{eq:minimizer_theta_less_0}
            \begin{aligned}
                \frac{\partial g_i(\theta_i)}{\partial \theta_i } &= - \thetah_{i} + \theta_i \underbrace{- \lambda}_{\theta_i < 0}  \stackrel{!}{=} 0  \longrightarrow \theta_i = \underbrace{\thetah_{i} +\lambda}_{ \leq 0} \\
                \theta_i^* &=  \underbrace{\thetah_i + \lambda}_{\leq0} \\
                &= min(0, \thetah_i  + \lambda) \\
            \end{aligned}
        \end{equation}

    \item 

        \begin{equation}
            \begin{aligned}
                \begin{cases}
                    \theta_i > 0 \longrightarrow \theta_i^* = \overbrace{1}^{\sign (\thetah_i)} \cdot \  max(0, \overbrace{\thetah_i}^{= |\thetah_i|} - \lambda) \\
                    \theta_i \leq 0 \longrightarrow \theta_i^* = min(0, \thetah_i + \lambda) 
                        = \underbrace{-1}_{\sign (\thetah_i)} \cdot \  max(0, \overbrace{-\thetah_i}^{ = |\thetah_i|}-\lambda)
                \end{cases}
            \end{aligned}
        \end{equation}

        By transforming the min function from \ref{eq:minimizer_theta_less_0} to a max function, we can combine the two cases in only one expression:

        \begin{equation}
        \begin{aligned}
            \theta_i^* = \sign(\thetah_i) max (|\thetah_i| - \lambda, 0)
        \end{aligned}
        \end{equation}

\end{enumerate}


